Building DAG of jobs...
Full Traceback (most recent call last):
  File "/home/mhu/miniconda3/envs/snake310/lib/python3.10/site-packages/snakemake/__init__.py", line 792, in snakemake
    success = workflow.execute(
  File "/home/mhu/miniconda3/envs/snake310/lib/python3.10/site-packages/snakemake/workflow.py", line 899, in execute
    self.persistence.lock()
  File "/home/mhu/miniconda3/envs/snake310/lib/python3.10/site-packages/snakemake/persistence.py", line 190, in lock
    raise snakemake.exceptions.LockException()
snakemake.exceptions.LockException: Error: Directory cannot be locked. Please make sure that no other Snakemake process is trying to create the same files in the following directory:
/gpfs/work2/0/prjs1616/gatk_paper_demo/script
If you are sure that no other instances of snakemake are running on this directory, the remaining lock was likely caused by a kill signal or a power loss. It can be removed with the --unlock argument.

LockException:
Error: Directory cannot be locked. Please make sure that no other Snakemake process is trying to create the same files in the following directory:
/gpfs/work2/0/prjs1616/gatk_paper_demo/script
If you are sure that no other instances of snakemake are running on this directory, the remaining lock was likely caused by a kill signal or a power loss. It can be removed with the --unlock argument.
unlocking
removed all locks
